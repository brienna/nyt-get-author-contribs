{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch stories by a certain author. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the [NYT Article Search API](https://developer.nytimes.com/docs/articlesearch-product/1/routes/articlesearch.json/get).\n",
    "\n",
    "Load dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../config.ini']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "\n",
    "# Usernames and passwords\n",
    "import configparser\n",
    "configs = configparser.ConfigParser()\n",
    "configs.read('../../config.ini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(query, page):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'http://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "    url = base_url + '?fq=' + query + '&api-key=' + configs['NYT']['ACCESS_KEY'] + '&page=' + str(page)\n",
    "    response = requests.get(url).json()\n",
    "    time.sleep(6)\n",
    "    return response\n",
    "\n",
    "def parse_response(response, data):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    articles = response['response']['docs'] \n",
    "    for article in articles: \n",
    "        # id\n",
    "        data['id'].append(article['_id'])\n",
    "        \n",
    "        # Date\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        data['date'].append(date)\n",
    "        \n",
    "        # Headline\n",
    "        data['headline'].append(article['headline']['main']) \n",
    "        \n",
    "        # Section\n",
    "        if 'section_name' in article:\n",
    "            data['section'].append(article['section_name'])\n",
    "        else:\n",
    "            data['section'].append(None)\n",
    "        \n",
    "        # News desk\n",
    "        if 'news_desk' in article:\n",
    "            data['news_desk'].append(article['news_desk'])\n",
    "        else:\n",
    "            data['news_desk'].append(None)\n",
    "        \n",
    "        # Document type\n",
    "        data['doc_type'].append(article['document_type'])\n",
    "        \n",
    "        # Type of material\n",
    "        if 'type_of_material' in article: \n",
    "            data['material_type'].append(article['type_of_material'])\n",
    "        else:\n",
    "            data['material_type'].append(None)\n",
    "            \n",
    "        # Keywords\n",
    "        keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "        data['keywords'].append(keywords)\n",
    "        \n",
    "        # Web URL\n",
    "        if 'web_url' in article:\n",
    "            data['url'].append(article['web_url'])\n",
    "            \n",
    "        # Author\n",
    "        if 'byline' in article:\n",
    "            data['byline'].append(article['byline']['original'])\n",
    "        else:\n",
    "            data['byline'].append(None)\n",
    "\n",
    "def send_query(query, data, date=None):\n",
    "    if date: # If date is provided, append to query string\n",
    "        query_str = query + date\n",
    "    else: \n",
    "        query_str = query\n",
    "    \n",
    "    page_num = 0\n",
    "    while True:\n",
    "        print('Querying string: ' + query_str + '\\n')\n",
    "        response = send_request(query_str, page_num)\n",
    "        offset = response['response']['meta']['offset']\n",
    "        hits = response['response']['meta']['hits']\n",
    "        \n",
    "        if offset > hits: \n",
    "            print('Done processing results.\\n')\n",
    "            return True\n",
    "        # If we have 2,000 hits or more, we will need to break down our query into date intervals\n",
    "        elif hits >= 2000: \n",
    "            print('We have over 2,000 hits.\\n')\n",
    "            # Send the same query again, once for each date interval\n",
    "            for date in q_dates:\n",
    "                send_query(query, data, date) \n",
    "            return True\n",
    "            \n",
    "        print('Processing results ' + str(offset) + '—' + str(min((offset + 10), hits)) + '/' + str(hits) + '...')\n",
    "        parse_response(response, data)\n",
    "        page_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get papers written by given author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 0—10/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 10—20/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 20—30/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 30—40/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 40—50/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 50—60/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 60—70/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 70—80/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 80—90/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 90—100/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 100—110/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 110—120/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Processing results 120—126/126...\n",
      "Querying string: byline:\"Shuaib Almosawa\"\n",
      "\n",
      "Done processing results.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author = 'Shuaib Almosawa'\n",
    "query = 'byline:\"' + author + '\"'\n",
    "data = {'headline': [],  \n",
    "            'date': [], \n",
    "            'doc_type': [],\n",
    "            'material_type': [],\n",
    "            'news_desk': [],\n",
    "            'section': [],\n",
    "            'keywords': [],\n",
    "            'url': [],\n",
    "            'id': [],\n",
    "            'byline': []}\n",
    "\n",
    "success = send_query(query, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save first csv, with all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as Shuaib_Almosawa_1.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    data_df = pd.DataFrame(data)\n",
    "    data_df['date'] = pd.to_datetime(data_df['date'])\n",
    "    data_df.to_csv('data/' + author.replace(' ', '_') + '_1.csv', index=False)\n",
    "    print('Saved as ' + author.replace(' ', '_') + '_1.csv.\\n')\n",
    "else:\n",
    "    print('Error.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save second csv, with results filtered to only those that contain the author in the byline. For some reason a few articles were returned that did not list the author in their bylines, but they seem to link to the author's articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as Shuaib_Almosawa_2.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = data_df[data_df['byline'].str.contains('Shuaib Almosawa')].reset_index(drop=True)\n",
    "data_df.to_csv('data/' + author.replace(' ', '_') + '_2.csv', index=False)\n",
    "print('Saved as ' + author.replace(' ', '_') + '_2.csv.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
